{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  Super-resolution: Perform superresolution on the image shown in notebook to enhance its resolution by factor 2. Show a qualitative comparison of original and reconstructed image. (i.e display original image and the image you created side by side) **[3 Marks]****\n",
    "**2. The above only helps us with a qualitative comparison. Let us now do a quantitative comparison. Compute the below given metrics:  **[1 Marks]**\n",
    "    - RMSE on predicted v/s ground truth high resolution image\n",
    "    - Peak SNR on predicted v/s ground truth high resolution image****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Using and Exploring OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "img = cv2.imread('./dog.jpg')\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 37,  51,  79],\n",
       "        [ 38,  52,  80],\n",
       "        [ 38,  52,  80],\n",
       "        ...,\n",
       "        [ 30,  55,  75],\n",
       "        [ 30,  54,  76],\n",
       "        [ 30,  54,  76]],\n",
       "\n",
       "       [[ 37,  51,  79],\n",
       "        [ 38,  52,  80],\n",
       "        [ 38,  52,  80],\n",
       "        ...,\n",
       "        [ 30,  55,  75],\n",
       "        [ 30,  54,  76],\n",
       "        [ 30,  54,  76]],\n",
       "\n",
       "       [[ 37,  51,  79],\n",
       "        [ 38,  52,  80],\n",
       "        [ 36,  53,  80],\n",
       "        ...,\n",
       "        [ 30,  55,  75],\n",
       "        [ 30,  54,  76],\n",
       "        [ 30,  54,  76]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 37, 103, 121],\n",
       "        [ 37, 103, 121],\n",
       "        [ 36, 105, 122],\n",
       "        ...,\n",
       "        [ 43,  82,  97],\n",
       "        [ 42,  80,  98],\n",
       "        [ 42,  80,  98]],\n",
       "\n",
       "       [[ 37, 103, 121],\n",
       "        [ 37, 103, 121],\n",
       "        [ 36, 105, 122],\n",
       "        ...,\n",
       "        [ 43,  82,  97],\n",
       "        [ 43,  81,  99],\n",
       "        [ 42,  80,  98]],\n",
       "\n",
       "       [[ 37, 103, 121],\n",
       "        [ 37, 103, 121],\n",
       "        [ 36, 105, 122],\n",
       "        ...,\n",
       "        [ 44,  83,  98],\n",
       "        [ 43,  81,  99],\n",
       "        [ 43,  81,  99]]], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imread('./dog.jpg',cv2.IMREAD_COLOR)\n",
    "cv2.imread('./dog.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imread('./dog.jpg',cv2.IMREAD_UNCHANGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image written to file-system :  True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    " #Incompleted code\n",
    "# read image as grey scale\n",
    "grey_img = cv2.imread('./dog.jpg')\n",
    "# save image\n",
    "status = cv2.imwrite('./dog.jpg',img)\n",
    "print(\"Image written to file-system : \",status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Dimension    :  (1365, 2048, 3)\n",
      "Image Height       :  1365\n",
      "Image Width        :  2048\n",
      "Number of Channels :  3\n"
     ]
    }
   ],
   "source": [
    "# read image\n",
    "img = cv2.imread('./dog.jpg', cv2.IMREAD_UNCHANGED)\n",
    "# get dimensions of image\n",
    "dimensions = img.shape\n",
    "# height, width, number of channels in image\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "channels = img.shape[2]\n",
    "print('Image Dimension    : ',dimensions)\n",
    "print('Image Height       : ',height)\n",
    "print('Image Width        : ',width)\n",
    "print('Number of Channels : ',channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Croping the picture to begin with 400*400 resolution image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Shape of the image (1365, 2048, 3)\n",
      "Shape of the cropped image (400, 400, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "  \n",
    "img = cv2.imread(\"./dog.jpg\") \n",
    "print(type(img)) \n",
    "  \n",
    "# Shape of the image \n",
    "print(\"Shape of the image\", img.shape) \n",
    "  \n",
    "# [rows, columns] \n",
    "crop = img[600:1000, 800:1200]   \n",
    "  \n",
    "print(\"Shape of the cropped image\",crop.shape)\n",
    "cv2.imshow('original', img) \n",
    "cv2.imshow('cropped', crop) \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resizing the image to 200*200 resolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dimensions :  (400, 400, 3)\n",
      "Resized Dimensions :  (200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Original Dimensions : ',crop.shape)\n",
    " \n",
    "scale_percent = 50 # percent of original size\n",
    "width = int(crop.shape[1] * scale_percent / 100)\n",
    "height = int(crop.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "resized = cv2.resize(crop, dim, interpolation = cv2.INTER_AREA)\n",
    "print('Resized Dimensions : ',resized.shape)\n",
    "cv2.imshow(\"Resized image\", resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model and RFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.235375\n",
      "Epoch 100 loss: 0.144749\n",
      "Epoch 200 loss: 0.142958\n",
      "Epoch 300 loss: 0.142957\n",
      "Epoch 400 loss: 0.142957\n",
      "Epoch 500 loss: 0.142957\n",
      "Epoch 600 loss: 0.142957\n",
      "Epoch 700 loss: 0.142957\n",
      "Epoch 800 loss: 0.142957\n",
      "Epoch 900 loss: 0.142957\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import log10, sqrt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Normalize the images to [-1, 1]\n",
    "scaler_img = preprocessing.MinMaxScaler(feature_range=(-1, 1)).fit(resized.reshape(-1, 1))\n",
    "resized_scaled = scaler_img.transform(resized.reshape(-1, 1)).reshape(resized.shape)\n",
    "crop_scaled = scaler_img.transform(crop.reshape(-1, 1)).reshape(crop.shape)\n",
    "\n",
    "# Convert to PyTorch tensors and move to the device\n",
    "resized_scaled = torch.tensor(resized_scaled).permute(2, 0, 1).float().to(device)  # Shape (3, h, w)\n",
    "crop_scaled = torch.tensor(crop_scaled).permute(2, 0, 1).float().to(device)        # Shape (3, h, w)\n",
    "\n",
    "# Create coordinate map function\n",
    "def create_coordinate_map(img):\n",
    "    num_channels, height, width = img.shape\n",
    "    w_coords = torch.arange(width).repeat(height, 1)\n",
    "    h_coords = torch.arange(height).repeat(width, 1).t()\n",
    "    w_coords = w_coords.reshape(-1)\n",
    "    h_coords = h_coords.reshape(-1)\n",
    "    X = torch.stack([h_coords, w_coords], dim=1).float().to(device)\n",
    "    Y = img.view(num_channels, height * width).t().float().to(device)\n",
    "    return X, Y\n",
    "\n",
    "# Linear Model definition\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create Random Fourier Features\n",
    "def create_rff_features(X, num_features, sigma):\n",
    "    rff = RBFSampler(n_components=num_features, gamma=1/(2 * sigma**2))\n",
    "    X = X.cpu().numpy()\n",
    "    X = rff.fit_transform(X)\n",
    "    return torch.tensor(X, dtype=torch.float32).to(device)\n",
    "\n",
    "# Training function\n",
    "def train(net, lr, X, Y, epochs, verbose=True):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} loss: {loss.item():.6f}\")\n",
    "    return loss.item()\n",
    "\n",
    "# RMSE Calculation\n",
    "def calculate_rmse(original, predicted):\n",
    "    # Flatten the (num_channels, height, width) to (num_pixels, num_channels)\n",
    "    original_flat = original.detach().cpu().numpy().reshape(-1, original.shape[0])  # Flatten height * width and keep channels\n",
    "    predicted_flat = predicted.detach().cpu().numpy().reshape(-1, predicted.shape[0])\n",
    "    \n",
    "    return sqrt(mean_squared_error(original_flat, predicted_flat))\n",
    "\n",
    "# PSNR Calculation\n",
    "def psnr(original, predicted):\n",
    "    original_flat = original.detach().cpu().numpy().reshape(-1, original.shape[0])\n",
    "    predicted_flat = predicted.detach().cpu().numpy().reshape(-1, predicted.shape[0])\n",
    "    \n",
    "    mse = mean_squared_error(original_flat, predicted_flat)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = 1.0  # Since images are normalized to [-1, 1]\n",
    "    psnr_value = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr_value\n",
    "\n",
    "\n",
    "# Generate coordinates and pixel values for the 200x200 image\n",
    "dog_X, dog_Y = create_coordinate_map(resized_scaled)\n",
    "X_rff = create_rff_features(dog_X, num_features=20000, sigma=0.008)  # Adjust num_features and sigma for better performance\n",
    "\n",
    "# Define and train the model\n",
    "net = LinearModel(X_rff.shape[1], 3).to(device)\n",
    "train(net, lr=0.005, X=X_rff, Y=dog_Y, epochs=1000)\n",
    "\n",
    "# Predict the pixel values for the 400x400 image\n",
    "coords_400, _ = create_coordinate_map(crop_scaled)\n",
    "X_rff_400 = create_rff_features(coords_400, num_features=20000, sigma=0.008)\n",
    "predicted_Y = net(X_rff_400).view(crop_scaled.shape)\n",
    "\n",
    "# Calculate RMSE and PSNR\n",
    "rmse = calculate_rmse(crop_scaled, predicted_Y)\n",
    "psnr_value = psnr(crop_scaled, predicted_Y)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"PSNR: {psnr_value}\")\n",
    "\n",
    "def plot_reconstructed_and_original_image(original_img, predicted_img, title=\"\"):\n",
    "    \"\"\"\n",
    "    Compare the original and predicted images.\n",
    "    \"\"\"\n",
    "    num_channels, height, width = original_img.shape\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[1, 1])\n",
    "\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1])\n",
    "\n",
    "    # Plot the reconstructed (predicted) image\n",
    "    ax0.imshow(predicted_img.detach().cpu().numpy().transpose(1, 2, 0))\n",
    "    ax0.set_title(\"Reconstructed Image\")\n",
    "\n",
    "    # Plot the original image\n",
    "    ax1.imshow(original_img.detach().cpu().numpy().transpose(1, 2, 0))\n",
    "    ax1.set_title(\"Original Image\")\n",
    "\n",
    "    for a in [ax0, ax1]:\n",
    "        a.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(title, y=0.9)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_reconstructed_and_original_image(crop_scaled, predicted_Y, title=\"Reconstructed vs Original\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
