{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://<Insert token here>@github.com/Ekanshsomani/es335-24-fall-assignment-2/\n",
    "%cd es335-24-fall-assignment-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have an image patch of size (50x50) that you want to compress using matrix factorization. To do this, you'll split the patch $[N\\times N]$ into two smaller matrices of size $[N\\times r]$ and $[r\\times N]$ using matrix factorization. Compute the compressed patch by multiplying these two matrices and compare the reconstructed image patch with the original patch. Compute the Root Mean Squared Error (RMSE) and Peak Signal-to-Noise Ratio (PSNR) between the original and reconstructed image patches.\n",
    "\n",
    "- Test different values for the low-rank $r = [5, 10, 25, 50]$.\n",
    "- Use Gradient Descent to learn the compressed matrices.\n",
    "- Display the reconstructed image patches, keeping the original pixel values outside the patch unchanged, and use your compressed matrix for the patch to show how well the reconstruction works.\n",
    "- Compute the RMSE and PSNR for each value of $r$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Remove all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set env CUDA_LAUNCH_BLOCKING=1\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Retina display\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# try:\n",
    "#     from einops import rearrange\n",
    "# except ImportError:\n",
    "#     %pip install einops\n",
    "#     from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('dog.jpg'):\n",
    "    print('dog.jpg exists')\n",
    "else:\n",
    "    !curl -o dog.jpg https://segment-anything.com/assets/gallery/AdobeStock_94274587_welsh_corgi_pembroke_CD.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for simple matrix factorization\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# gradient descent\n",
    "def fac_grad(A: torch.tensor, r: int, epochs: int):\n",
    "    A = A.to(device)\n",
    "    n = A.shape[0]\n",
    "    U = torch.rand(n, r, requires_grad = True, device = device)\n",
    "    V = torch.rand(r, n, requires_grad = True, device = device)\n",
    "\n",
    "    losses = []\n",
    "    optimizer = optim.Adam([U, V], lr = 0.01)\n",
    "    # mask = ~torch.isnan(A)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        diff_matrix = (U @ V) - A\n",
    "        # diff_vector = diff_matrix[mask]\n",
    "        loss = torch.norm(diff_matrix)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%50 == 0:\n",
    "            losses.append(loss)\n",
    "    return U, V, losses\n",
    "\n",
    "# wals method\n",
    "def fac_wals(A: torch.tensor, r: int, epochs: int):\n",
    "    A = A.to(device)\n",
    "    n = A.shape[0]\n",
    "    U = torch.rand(n, r, requires_grad = True, device = device)\n",
    "    V = torch.rand(r, n, requires_grad = True, device = device)\n",
    "\n",
    "    losses = []\n",
    "    optimizer1 = optim.Adam([U], lr = 0.01)\n",
    "    optimizer2 = optim.Adam([V], lr = 0.01)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # fix V, update U\n",
    "        diff_matrix = (U @ V) - A\n",
    "        loss = torch.norm(diff_matrix)\n",
    "        optimizer1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        # fix U, update V\n",
    "        diff_matrix = (U @ V) - A\n",
    "        loss = torch.norm(diff_matrix)\n",
    "        optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        if i%50 == 0:\n",
    "            losses.append(loss)\n",
    "\n",
    "    return U, V, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the functions for image factorization\n",
    "\n",
    "# gradient descent\n",
    "def fac_grad_loop(A: torch.tensor, r: int, epochs: int):\n",
    "    A = A.to(device)\n",
    "    n, _, d = A.shape\n",
    "\n",
    "    U = torch.zeros(n, r, d, device = device)\n",
    "    V = torch.zeros(r, n, d, device = device)\n",
    "    losses = [[], [], []]\n",
    "    for i in range(d):\n",
    "        U[:, :, i], V[:, :, i], losses[i] = fac_wals(A[:, :, i], r, epochs)\n",
    "\n",
    "    return U, V, losses\n",
    "\n",
    "# WALS method\n",
    "def fac_wals_loop(A: torch.tensor, r: int, epochs: int):\n",
    "    A = A.to(device)\n",
    "    n, _, d = A.shape\n",
    "\n",
    "    U = torch.zeros(n, r, d, device = device)\n",
    "    V = torch.zeros(r, n, d, device = device)\n",
    "    losses = [[], [], []]\n",
    "\n",
    "    for i in range(d):\n",
    "        U[:, :, i], V[:, :, i], losses[i] = fac_wals(A[:, :, i], r, epochs)\n",
    "\n",
    "    return U, V, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, sqrt\n",
    "\n",
    "def diffs(org: torch.tensor, comp: torch.tensor, max_pixel: float = 1.0) -> tuple[float, float]:\n",
    "\n",
    "    mse = torch.mean((org - comp) ** 2).item()\n",
    "\n",
    "    if mse < 1e-8: return 0.0, float('inf')\n",
    "\n",
    "    return sqrt(mse), 10 * log10((max_pixel ** 2) / mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def createPlots(patch: torch.tensor, crop: torch.tensor, y: int, x: int,\n",
    "                gfactorize = fac_grad_loop, wfactorize = fac_wals_loop, epochs: int = 1000):\n",
    "    r_vals = [5, 10, 25, 50]\n",
    "\n",
    "    gd_psnr = []\n",
    "    gd_rms = []\n",
    "    wals_psnr = []\n",
    "    wals_rms = []\n",
    "\n",
    "    fig, axs = plt.subplots(4, 3, figsize = (14, 18))\n",
    "    for i, r in enumerate(r_vals):\n",
    "        U_grad, V_grad, _ = gfactorize(patch, r, epochs)\n",
    "        U_wals, V_wals, _ = wfactorize(patch, r, epochs)\n",
    "\n",
    "        crop_grad = crop.clone()\n",
    "        crop_wals = crop.clone()\n",
    "\n",
    "        for j in range(3):\n",
    "            crop_grad[y:y+50, x:x+50, j] = (U_grad[:, :, j] @ V_grad[:, :, j]).detach()\n",
    "            crop_wals[y:y+50, x:x+50, j] = (U_wals[:, :, j] @ V_wals[:, :, j]).detach()\n",
    "\n",
    "        rms, psnr = diffs(patch, crop_grad[y:y+50, x:x+50, :])\n",
    "        gd_rms.append(rms)\n",
    "        gd_psnr.append(psnr)\n",
    "\n",
    "        rms, psnr = diffs(patch, crop_wals[y:y+50, x:x+50, :])\n",
    "        wals_rms.append(rms)\n",
    "        wals_psnr.append(psnr)\n",
    "\n",
    "        axs[i, 0].imshow(crop.cpu().numpy())\n",
    "        axs[i, 1].imshow(crop_grad.cpu().numpy())\n",
    "        axs[i, 2].imshow(crop_wals.cpu().numpy())\n",
    "        # im_wals is the patch, that we need to change at x, y and display the crop in axs[i, 2]\n",
    "\n",
    "    for ax, col in zip(axs[0], ['Original', 'Gradient Descent', 'WALS']):\n",
    "        ax.set_title(col)\n",
    "\n",
    "    for ax, r in zip(axs[:,0], r_vals):\n",
    "        ax.set_ylabel(f'r = {r}', size='large')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig1, axs1, = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    # PSNR comparison\n",
    "\n",
    "    axs1[0].plot(r_vals, gd_psnr, label='Gradient Descent PSNR', marker='o')\n",
    "    axs1[0].plot(r_vals, wals_psnr, label='WALS PSNR', marker='x')\n",
    "    axs1[0].set_xlabel('r values')\n",
    "    axs1[0].set_ylabel('PSNR')\n",
    "    axs1[0].set_title('PSNR Comparison')\n",
    "    axs1[0].legend()\n",
    "    axs1[0].grid()\n",
    "\n",
    "    # RMS comparison\n",
    "    axs1[1].plot(r_vals, gd_rms, label='Gradient Descent RMS', marker='o')\n",
    "    axs1[1].plot(r_vals, wals_rms, label='WALS RMS', marker='x')\n",
    "    axs1[1].set_xlabel('r values')\n",
    "    axs1[1].set_ylabel('RMSE')\n",
    "    axs1[1].set_title('RMSE Comparison')\n",
    "    axs1[1].grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from sklearn import preprocessing\n",
    "\n",
    "img = torchvision.io.read_image(\"dog.jpg\")\n",
    "scaler_img = preprocessing.MinMaxScaler().fit(img.reshape(-1, 1))\n",
    "img_scaled = scaler_img.transform(img.reshape(-1, 1)).reshape(img.shape)\n",
    "img_scaled = torch.tensor(img_scaled)\n",
    "\n",
    "\n",
    "crop = torchvision.transforms.functional.crop(img_scaled, 600, 800, 300, 300)\n",
    "patch1 = torchvision.transforms.functional.crop(crop, 0, 0, 50, 50)\n",
    "patch2 = torchvision.transforms.functional.crop(crop, 50, 50, 50, 50)\n",
    "patch3 = torchvision.transforms.functional.crop(crop, 175, 75, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = crop.permute(1, 2, 0)\n",
    "patch1 = patch1.permute(1, 2, 0)\n",
    "patch2 = patch2.permute(1, 2, 0)\n",
    "patch3 = patch3.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlots(patch1, crop, 0, 0, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlots(patch2, crop, 50, 50, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlots(patch3, crop, 175, 75, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlots(patch1, crop, 0, 0, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlots(patch2, crop, 50, 50, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createPlots(patch3, crop, 175, 75, epochs=500)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
